2022-09-30 15:38:04,318	INFO trainable.py:160 -- Trainable.setup took 21.786 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2022-09-30 15:38:04,319	WARNING util.py:65 -- Install gputil for GPU system monitoring.
[33m(raylet)[39m [2022-09-30 15:38:06,019 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4611432448; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 33 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 930, 'num_env_steps_trained': 930, 'num_agent_steps_sampled': 930, 'num_agent_steps_trained': 930}
training epoch 0 33 68.0 28.393939393939394
log_result(...)
Algorithm.train() result: A3C -> 33 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 1830, 'num_env_steps_trained': 1830, 'num_agent_steps_sampled': 1830, 'num_agent_steps_trained': 1830}
training epoch 1 66 84.0 27.893939393939394
[33m(raylet)[39m [2022-09-30 15:38:16,030 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4610633728; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 31 episodes
ON TRAIN {'learner': {'default_policy': {'learner_stats': {'allreduce_latency': 0.0, 'grad_gnorm': 30.0, 'cur_lr': 0.001, 'entropy_coeff': 0.01, 'policy_entropy': 6.827186584472656, 'policy_loss': 8.277653694152832, 'vf_loss': 47.50462341308594, 'total_loss': 31.961692810058594}}}, 'num_env_steps_sampled': 2410, 'num_env_steps_trained': 2410, 'num_agent_steps_sampled': 2410, 'num_agent_steps_trained': 2410}
training epoch 2 97 84.0 24.938144329896907
log_result(...)
Algorithm.train() result: A3C -> 19 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 2940, 'num_env_steps_trained': 2940, 'num_agent_steps_sampled': 2940, 'num_agent_steps_trained': 2940}
training epoch 3 100 84.0 25.2
[33m(raylet)[39m [2022-09-30 15:38:26,054 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4618891264; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 21 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 3550, 'num_env_steps_trained': 3550, 'num_agent_steps_sampled': 3550, 'num_agent_steps_trained': 3550}
training epoch 4 100 78.0 24.41
[33m(raylet)[39m [2022-09-30 15:38:36,080 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4616491008; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 18 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 4200, 'num_env_steps_trained': 4200, 'num_agent_steps_sampled': 4200, 'num_agent_steps_trained': 4200}
training epoch 5 100 78.0 25.58
log_result(...)
Algorithm.train() result: A3C -> 20 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 4960, 'num_env_steps_trained': 4960, 'num_agent_steps_sampled': 4960, 'num_agent_steps_trained': 4960}
training epoch 6 100 81.0 29.24
[33m(raylet)[39m [2022-09-30 15:38:46,098 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4615802880; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 17 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 5570, 'num_env_steps_trained': 5570, 'num_agent_steps_sampled': 5570, 'num_agent_steps_trained': 5570}
training epoch 7 100 91.0 32.01
log_result(...)
Algorithm.train() result: A3C -> 16 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 6110, 'num_env_steps_trained': 6110, 'num_agent_steps_sampled': 6110, 'num_agent_steps_trained': 6110}
training epoch 8 100 91.0 33.82
[33m(raylet)[39m [2022-09-30 15:38:56,126 E 31443 31468] (raylet) file_system_monitor.cc:105: /tmp/ray/session_2022-09-30_15-37-42_610259_31322 is over 95% full, available space: 4613541888; capacity: 125844406272. Object creation will fail if spilling is required.
log_result(...)
Algorithm.train() result: A3C -> 26 episodes
ON TRAIN {'learner': {}, 'num_env_steps_sampled': 6920, 'num_env_steps_trained': 6920, 'num_agent_steps_sampled': 6920, 'num_agent_steps_trained': 6920}
training epoch 9 100 91.0 34.52
[38.0, 25.0, 40.0, 47.0, 32.0, 47.0, 38.0, 27.0, 30.0, 62.0, 12.0, 15.0, 14.0, 77.0, 61.0, 32.0, 70.0, 16.0, 16.0, 23.0, 36.0, 19.0, 13.0, 12.0, 33.0, 15.0, 25.0, 81.0, 67.0, 44.0, 32.0, 53.0, 34.0, 56.0, 45.0, 51.0, 12.0, 22.0, 29.0, 75.0, 33.0, 22.0, 91.0, 64.0, 17.0, 16.0, 53.0, 28.0, 12.0, 15.0, 38.0, 29.0, 84.0, 33.0, 25.0, 19.0, 21.0, 24.0, 58.0, 26.0, 26.0, 28.0, 40.0, 69.0, 19.0, 28.0, 30.0, 22.0, 69.0, 24.0, 36.0, 28.0, 27.0, 30.0, 25.0, 58.0, 38.0, 67.0, 24.0, 12.0, 25.0, 72.0, 19.0, 18.0, 26.0, 13.0, 44.0, 35.0, 23.0, 39.0, 29.0, 27.0, 16.0, 19.0, 21.0, 27.0, 20.0, 55.0, 15.0, 25.0]
['self', 'mode']
  0%|          | 0/10 [00:00<?, ?it/s]


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:05<00:06,  1.11s/it, Episode=3, Accumulated Reward=18, Average Reward=1, Length=18, Steps=119]




 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:15<00:04,  2.22s/it, Episode=7, Accumulated Reward=36, Average Reward=1, Length=36, Steps=351]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:21<00:00,  2.11s/it, Episode=9, Accumulated Reward=75, Average Reward=1, Length=75, Steps=469]
[None]
Job done